[{"categories":null,"contents":" Hello World A sample go program is show here.\npackage main import \u0026#34;fmt\u0026#34; func main() { message := greetMe(\u0026#34;world\u0026#34;) fmt.Println(message) } func greetMe(name string) string { return \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34; } Run the program as below:\n$ go run hello.go Variables Normal Declaration:\nvar msg string msg = \u0026#34;Hello\u0026#34; Shortcut:\nmsg := \u0026#34;Hello\u0026#34; Constants const Phi = 1.618 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://melaniebrg.github.io/notes/go/basic/introduction/","summary":" Hello World A sample go program is show here.\npackage main import \u0026#34;fmt\u0026#34; func main() { message := greetMe(\u0026#34;world\u0026#34;) fmt.Println(message) } func greetMe(name string) string { return \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34; } Run the program as below:\n$ go run hello.go Variables Normal Declaration:\nvar msg string msg = \u0026#34;Hello\u0026#34; Shortcut:\nmsg := \u0026#34;Hello\u0026#34; Constants const Phi = 1.618 ","tags":null,"title":"Go পরিচিতি"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://melaniebrg.github.io/notes/go/basic/_index.bn/","summary":"","tags":null,"title":"Go বেসিক"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://melaniebrg.github.io/notes/go/advanced/_index.bn/","summary":"","tags":null,"title":"অ্যাডভান্সড"},{"categories":null,"contents":" Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string` Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0} Pointers func main () { b := *getPointer() fmt.Println(\u0026#34;Value is\u0026#34;, b) func getPointer () (myPointer *int) { a := 234 return \u0026amp;a a := new(int) *a = 234 Pointers point to a memory location of a variable. Go is fully garbage-collected.\nType Conversion i := 2 f := float64(i) u := uint(i) Slice slice := []int{2, 3, 4} slice := []byte(\u0026#34;Hello\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://melaniebrg.github.io/notes/go/basic/types/","summary":"Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string` Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0} Pointers func main () { b := *getPointer() fmt.","tags":null,"title":"বেসিক টাইপ সমূহ"},{"categories":null,"contents":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) Switch switch day { case \u0026#34;sunday\u0026#34;: // cases don\u0026#39;t \u0026#34;fall through\u0026#34; by default! fallthrough case \u0026#34;saturday\u0026#34;: rest() default: work() } Loop for count := 0; count \u0026lt;= 10; count++ { fmt.Println(\u0026#34;My counter is at\u0026#34;, count) } entry := []string{\u0026#34;Jack\u0026#34;,\u0026#34;John\u0026#34;,\u0026#34;Jones\u0026#34;} for i, val := range entry { fmt.Printf(\u0026#34;At position %d, the character %s is present\\n\u0026#34;, i, val) n := 0 x := 42 for n != x { n := guess() } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://melaniebrg.github.io/notes/go/basic/flow-control/","summary":"Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) Switch switch day { case \u0026#34;sunday\u0026#34;: // cases don\u0026#39;t \u0026#34;fall through\u0026#34; by default! fallthrough case \u0026#34;saturday\u0026#34;: rest() default: work() } Loop for count := 0; count \u0026lt;= 10; count++ { fmt.Println(\u0026#34;My counter is at\u0026#34;, count) } entry := []string{\u0026#34;Jack\u0026#34;,\u0026#34;John\u0026#34;,\u0026#34;Jones\u0026#34;} for i, val := range entry { fmt.","tags":null,"title":"Flow Control"},{"categories":null,"contents":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://melaniebrg.github.io/notes/go/advanced/files/","summary":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) ","tags":null,"title":"ফাইল ম্যানিপুলেশন"},{"categories":null,"contents":" Variable NAME=\u0026#34;John\u0026#34; echo $NAME echo \u0026#34;$NAME\u0026#34; echo \u0026#34;${NAME} Condition if [[ -z \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is empty\u0026#34; elif [[ -n \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is not empty\u0026#34; fi ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://melaniebrg.github.io/notes/bash/basic/","summary":" Variable NAME=\u0026#34;John\u0026#34; echo $NAME echo \u0026#34;$NAME\u0026#34; echo \u0026#34;${NAME} Condition if [[ -z \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is empty\u0026#34; elif [[ -n \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is not empty\u0026#34; fi ","tags":null,"title":"Bash Variables"},{"categories":null,"contents":"Introduction: In 1991, computer scientist Mark Weiser introduced the concept of \u0026ldquo;ubiquitous computing,\u0026rdquo; envisioning a world where technology seamlessly integrates into our daily lives. Today, we\u0026rsquo;ll explore whether we are already living in a world of ubiquitous computing, highlighting both what has been achieved and what remains on the horizon.\nWhat is \u0026ldquo;Ubiquitous Computing\u0026rdquo; ? Ubiquitous computing, often referred to as \u0026ldquo;pervasive computing,\u0026rdquo; is a paradigm where computing technology is seamlessly embedded in the environment, making it an invisible and integral part of our daily lives. It envisions a world where computers are so interwoven into our surroundings that they operate unnoticed but provide significant benefits.\nAspects proving ubiquitous computing is already here: Smartphones and Wearables: We carry powerful computers in our pockets and wear them on our wrists. Smartphones and wearables have become extensions of ourselves, offering instant access to information, communication, and a wide range of applications. Internet of Things (IoT): Our homes are filled with interconnected devices that communicate with each other, from thermostats that adjust temperatures based on our preferences to smart speakers that respond to voice commands. Voice Assistants: Virtual assistants like Siri, Alexa, and Google Assistant have made it easy to interact with technology using natural language, becoming an integral part of our daily routines. Aspects showing the path forward: Interoperability: For a more seamless experience, devices need to work together effortlessly. We need standardized communication protocols to ensure that different gadgets can collaborate effectively. Privacy and Security: Protecting our data and privacy in an interconnected world is an ongoing concern. Strengthening security measures and promoting user education is crucial. Energy Efficiency: Ubiquitous computing devices should be energy-efficient and rely on sustainable power sources to reduce their environmental impact. What about ubiquitous Mixed Reality Head-Mounted Displays (MR HMDs) In a future where Mixed Reality Head-Mounted Displays (MR HMDs) are as ubiquitous as smartphones, the applications available on the MR app store will significantly impact how we live, work, and interact with the digital and physical worlds.\nHere are some of the most downloaded applications that I envision and the reasons behind their popularity:\nHealth and Wellness Assistants: These apps will provide personalized health and wellness guidance, helping users monitor their physical activity, nutrition, and mental health. Virtual trainers and health advisors will guide users through workouts, track their progress, and offer immediate feedback for a healthier lifestyle.\nAugmented Learning and Education Apps: With MR HMDs, learning can become an immersive experience. These apps will offer interactive and educational content, taking students on virtual field trips, dissecting 3D models, and providing real-time language translation for global learning.\nMixed Reality Social Networking: Why: MR HMDs will bring people together in virtual environments, allowing them to socialize and collaborate in new and exciting ways. Users can meet in shared spaces, play games, attend virtual events, and work together, regardless of physical distances, making social networking more immersive and personal.\n","date":"October 31, 2023","hero":"/posts/hci/ubiquitous/ubi.png","permalink":"https://melaniebrg.github.io/posts/hci/ubiquitous/","summary":"Introduction: In 1991, computer scientist Mark Weiser introduced the concept of \u0026ldquo;ubiquitous computing,\u0026rdquo; envisioning a world where technology seamlessly integrates into our daily lives. Today, we\u0026rsquo;ll explore whether we are already living in a world of ubiquitous computing, highlighting both what has been achieved and what remains on the horizon.\nWhat is \u0026ldquo;Ubiquitous Computing\u0026rdquo; ? Ubiquitous computing, often referred to as \u0026ldquo;pervasive computing,\u0026rdquo; is a paradigm where computing technology is seamlessly embedded in the environment, making it an invisible and integral part of our daily lives.","tags":null,"title":"Ubiquitous Computing: A Vision and Reality"},{"categories":null,"contents":"Mobile phones have come a long way in terms of design over the past decade. In this blog post, we\u0026rsquo;ll take a closer look at the evolution of mobile phone design and shape, with a specific focus on weight, thickness, and display size.\nWeight Matters: Mobile phone manufacturers have been on a mission to make our devices smaller and lighter. While the average weight of mobile phones has remained relatively consistent, it\u0026rsquo;s worth noting that modern high-end smartphones now pack more features into smaller, lighter packages. However, the quest for feature-rich phones has driven the trend towards slightly heavier devices. The finish of a phone, such as metal or tempered glass, can add to its weight.\nThin is In: Slimness has become a defining factor in mobile phone design. The trend towards thinner phones gained momentum with iconic models like the Motorola RAZR V3. High-end phones have increasingly embraced slim profiles, with a notable gap emerging between high-end and average devices. Nevertheless, there\u0026rsquo;s a limit to how thin a phone can be while remaining durable. Extremely slim phones may not withstand regular use, and there\u0026rsquo;s a consensus that most users don\u0026rsquo;t need them to be any slimmer. So, high-end smartphone thickness may find its ideal balance in the near future.\nBigger Displays: When it comes to display size, the mantra seems to be \u0026ldquo;bigger is better.\u0026rdquo; Advances in screen resolution have made larger screens more appealing. While some argue that smaller, high-resolution displays offer a sharper image, most users prefer larger screens for their everyday tasks. Phone screens have been steadily growing in size, with some crossing the 5-inch threshold. However, it\u0026rsquo;s uncertain whether phones will continue to grow beyond this point, as ergonomic considerations may limit further size increases.\n","date":"October 30, 2023","hero":"/posts/hci/current/evolution.png","permalink":"https://melaniebrg.github.io/posts/hci/current/","summary":"Mobile phones have come a long way in terms of design over the past decade. In this blog post, we\u0026rsquo;ll take a closer look at the evolution of mobile phone design and shape, with a specific focus on weight, thickness, and display size.\nWeight Matters: Mobile phone manufacturers have been on a mission to make our devices smaller and lighter. While the average weight of mobile phones has remained relatively consistent, it\u0026rsquo;s worth noting that modern high-end smartphones now pack more features into smaller, lighter packages.","tags":null,"title":"The shape of smartphones"},{"categories":null,"contents":"In today\u0026rsquo;s fast-paced world, technology has become an integral part of our daily lives, and it\u0026rsquo;s continually reshaping the way we go about our routines. Augmented Reality (AR) is one such technology that holds the potential to enhance human abilities and make our lives more efficient and enjoyable. In this blog article, I present an innovative project aimed at transforming the way we plan meals, manage kitchen inventory, and shop for groceries – all through the lens of AR.\nEnhanced Augmented Alimentation: AR Meal Planning, Inventory Management, and Shopping Assistance Concept: An integrated AR application that combines meal planning, kitchen inventory management, and shopping assistance to streamline the entire food preparation process.\nInteraction:\nEnhanced meal planning Meal Planning: Users input their dietary preferences and select meals they\u0026rsquo;d like to prepare for a set duration (e.g., a week). Inventory Scanning: Users scan the barcodes or visually identify food items in their kitchen, which the AR app recognizes and adds to their virtual kitchen inventory. Auto-Generated Shopping List: The app cross-references the chosen meals with the inventory and generates a shopping list for missing ingredients. Enhanced Shopping Assistance Grocery Store Navigation: When users go shopping, the AR app provides optimal in-store navigation to locate items, along with real-time stock updates.\nEnhanced Cooking Assistance Cooking Assistant: For each meal, the app offers step-by-step cooking instructions and timers using AR overlays.\nPrototype: Let\u0026rsquo;s break down the components of the prototype:\nLogging In / Signing Up: Users start by logging in or signing up. This step ensures that the app can personalize their meal planning and shopping experience. Meal Planning, Inventory Management and Grocery List Generation: Users specify what they\u0026rsquo;d like to eat for the week, along with the number of people. They use camera buttons to scan the food items they already have in their kitchen.The AI component processes the scanned items and generates a list of groceries needed for the planned meals.\nShopping Optimization: Users have the option to click on \u0026ldquo;Go shopping,\u0026rdquo; which connects the app to their AR headset. The app uses AR technology to provide an optimized path for shopping in their favorite grocery store.\nEvaluation I tried this prototype on my family and here are some feed back on the different functionnalities :\nThe login/sign-up process was straightforward and user-friendly. They didn\u0026rsquo;t encounter any issues during this stage. One suggestion is to consider adding a navigation bar at the bottom of the app. It would make it more convenient to switch between different sections of the app, especially when navigating through the AR headset. This could improve the overall user experience. ","date":"October 21, 2023","hero":"/posts/hci/futur/futur.png","permalink":"https://melaniebrg.github.io/posts/hci/futur/","summary":"In today\u0026rsquo;s fast-paced world, technology has become an integral part of our daily lives, and it\u0026rsquo;s continually reshaping the way we go about our routines. Augmented Reality (AR) is one such technology that holds the potential to enhance human abilities and make our lives more efficient and enjoyable. In this blog article, I present an innovative project aimed at transforming the way we plan meals, manage kitchen inventory, and shop for groceries – all through the lens of AR.","tags":null,"title":"Enhancing human habilities in the age of Augmented Reality"},{"categories":null,"contents":"The \u0026ldquo;FeetThrough: Electrotactile Foot Interface\u0026rdquo; is an interesting haptic input device that falls into the category of a sensory or haptic user interface. It aims to provide haptic feedback to the user\u0026rsquo;s feet, enhancing their sensory experience during foot-based activities, such as walking, stepping on virtual textures, or interacting with virtual environments. While it\u0026rsquo;s a promising concept with potential benefits, there are factors that have contributed to its limited success or challenges it may face in the future.\nChallenges and Potential Reasons for Limited Success:\nAcceptance and Adoption: The adoption of such a device is a significant challenge. Users may not be accustomed to receiving sensory input through their feet in the way they are through their hands, and it may take time for people to adapt to and accept this form of haptic feedback. Technical Limitations: The electrotactile technology may have technical limitations that hinder its widespread adoption. Issues such as power consumption, durability, and the complexity of the device can pose challenges to its practical use. Cost and Accessibility: Developing and manufacturing such devices could be costly, making them inaccessible to a broader audience. If the technology remains prohibitively expensive, it may not achieve widespread use. User Comfort and Safety: Ensuring user comfort and safety while using electrotactile stimulation is crucial. If users find the sensations uncomfortable or if there are any safety concerns (e.g., electrical shocks), it could deter adoption. ","date":"October 20, 2023","hero":"/posts/hci/failed_input/fail.png","permalink":"https://melaniebrg.github.io/posts/hci/failed_input/","summary":"The \u0026ldquo;FeetThrough: Electrotactile Foot Interface\u0026rdquo; is an interesting haptic input device that falls into the category of a sensory or haptic user interface. It aims to provide haptic feedback to the user\u0026rsquo;s feet, enhancing their sensory experience during foot-based activities, such as walking, stepping on virtual textures, or interacting with virtual environments. While it\u0026rsquo;s a promising concept with potential benefits, there are factors that have contributed to its limited success or challenges it may face in the future.","tags":null,"title":"Input Devices and Interaction Paradigms"},{"categories":["unity"],"contents":"Introduction After a 12-hour class at the Institut Polytechnique de Paris, where we explored the fundamentals of Unity, Pauline Spinga and I embarked on a creative project to model and develop a music-themed platform game named \u0026ldquo;Virtuoso\u0026rdquo;. In this game, players step into the shoes of Vivaldi, a character who has lost his piano and guitar and must embark on a journey through the changing seasons to recover his instruments while collecting musical notes along the way.\n3D Modeling Our journey began with 3D modeling using Blender. We crafted various elements such as the ground, bridges, trees, houses, mushrooms, and even a snowman. For the musical notes, we sourced a model from an external website. And we included our Blender modelisation projects : my guitar and Pauline\u0026rsquo;s piano !\nPlayer Animation and Controls To bring our character to life, we incorporated animations and controls. We obtained these assets from Mixamo, which provided both the character\u0026rsquo;s appearance and animations.\nHealth system In \u0026ldquo;Virtuoso,\u0026rdquo; players confront a formidable adversary – the snowman, who relentlessly hurls snow bullets at them. To intensify the gaming experience, we introduced a health system that equips the player with three lives. Each time a player is hit by a snow bullet, they lose one of their lives. Moreover, if the player inadvertently falls into the water, it results in an immediate game over.\nMusic, Level Progression and User Interface When you first launch the game, you will find yourself on the starting page, where you can choose to begin or quit the game. The game rules are clearly displayed for your reference.\nVirtuoso is accompanied by Vivaldi\u0026rsquo;s music, and the user interface provides essential information, displaying the player\u0026rsquo;s remaining lives, the status of the piano and guitar (whether found or not), and the collected notes. Furthermore an exit button is available.\nThe game offers two distinct outcomes:\nWhen the player loses (due to falling into the water or running out of lives), a \u0026ldquo;Game Over\u0026rdquo; screen is displayed. On the other hand, when the player successfully recovers both instruments, they are greeted with a \u0026ldquo;Win\u0026rdquo; screen, and their level progresses, ranging from a novice musician to a virtuoso, based on the number of notes collected. In either case, you have the option to return to the starting page or restart the game.\n","date":"October 10, 2023","hero":"/posts/cg/unity-project/front.png","permalink":"https://melaniebrg.github.io/posts/cg/unity-project/","summary":"Introduction After a 12-hour class at the Institut Polytechnique de Paris, where we explored the fundamentals of Unity, Pauline Spinga and I embarked on a creative project to model and develop a music-themed platform game named \u0026ldquo;Virtuoso\u0026rdquo;. In this game, players step into the shoes of Vivaldi, a character who has lost his piano and guitar and must embark on a journey through the changing seasons to recover his instruments while collecting musical notes along the way.","tags":null,"title":"3D platform game Unity"},{"categories":null,"contents":"In this article, we will delve into the visionary concepts put forth by Ivan Sutherland in his seminal paper, \u0026ldquo;The Ultimate Display\u0026rdquo; written in 1965. He envisaged several possibilities, some of which have already materialized, while others remain on the horizon:\nAdvanced Graphics and Visualization: Sutherland anticipated the development of computer displays capable of rendering plot, curves or graphics. Today, modern graphics cards and software can produce highly detailed and realistic 2D and 3D graphics for applications such as gaming and scientific simulations.\nUser Interfaces: He explored various input methods, including light pens, styluses, joysticks, and voice commands, as tools for human-computer interaction. These methods are now commonplace, and we continue to witness innovations like touchscreens and gesture-based interfaces.\nKinesthetic Displays: Sutherland introduced the concept of kinesthetic displays, providing tactile feedback to users\nEye Tracking: He speculated about using eye movements to control computers, and today, eye-tracking technology is used by surgeons to consult information on a computer while operating on a patient, vehicles to obtain information about the driver’s attention or virtual reality headsets.\nWhat Could Become Reality in the Future: Haptic Feedback: Sutherland\u0026rsquo;s idea of kinesthetic displays may progress further. In the future, we could experience more advanced haptic feedback systems, providing even more realistic physical sensations in virtual environments.\nFully Immersive Environments: The concept of a room where computers control everything could evolve into even more immersive environments, pushing the boundaries between the physical and virtual realms. As technology advances, we may witness increasingly realistic and interactive simulated worlds.\n","date":"October 10, 2023","hero":"/posts/hci/ultimate_display/display.png","permalink":"https://melaniebrg.github.io/posts/hci/ultimate_display/","summary":"In this article, we will delve into the visionary concepts put forth by Ivan Sutherland in his seminal paper, \u0026ldquo;The Ultimate Display\u0026rdquo; written in 1965. He envisaged several possibilities, some of which have already materialized, while others remain on the horizon:\nAdvanced Graphics and Visualization: Sutherland anticipated the development of computer displays capable of rendering plot, curves or graphics. Today, modern graphics cards and software can produce highly detailed and realistic 2D and 3D graphics for applications such as gaming and scientific simulations.","tags":null,"title":"The Ultimate Display"},{"categories":null,"contents":"Exploring the Pioneering HCI Research of Dr. Elizabeth Churchill Brief introduction Dr. Elizabeth Churchill, currently a Director of User Experience at Google in Mountain View, California, has drawn on social, computer, engineering and data sciences to create innovative end-user applications and services for the past 20 years.\nAcademic Background She holds a PhD from the University of Cambridge, an honorary Doctor of Science (DSc.) from the University of Sussex, and in September will be awarded an honorary doctorate from the University of Stockholm. In 2016 she received a Citris-Banatao Institute Award Athena Award for Women in Technology for her Executive Leadership.\nCurrent Research Projects Dr. Elizabeth Churchill, a distinguished research scientist, is currently delving into the dynamic field of Human-Computer Interaction (HCI). Her primary research interests revolve around designing and evaluating technologies that enhance communication and connection among individuals.\nSpecifically, Dr. Churchill is focused on exploring novel HCI solutions for social contexts. Her work encompasses various facets of human interaction, including community-building, collaboration, communication enhancement, coordination, consensus-building, competition, compassion, and creativity. Her research not only seeks to design interactive applications but also to understand how people ingeniously integrate and adapt these technologies into their daily lives.\nMoreover, Dr. Churchill is intrigued by the evolving digital media landscape and \u0026ldquo;Internet ethnoscapes,\u0026rdquo; a term she borrows from Arjun Appadurai. This concept refers to the ever-shifting dynamics of individuals and groups in digital spaces, such as online communities and social media platforms.\nHer research approach takes a cross-cultural perspective, drawing from her experiences working in Japan, the United States, and the United Kingdom. She is keenly interested in how social technologies and social media are adopted and adapted within diverse cultural and social settings.\nDr. Churchill\u0026rsquo;s research is informed by a multidisciplinary approach, integrating insights from psychology, sociology, anthropology, cultural studies, urban studies, and film studies. Her professional interests span various areas within HCI, including interactive technology design, social media, augmented and virtual reality, and user experience (UX). In her quest to understand and improve the human-computer interaction landscape, she continues to innovate and contribute to the HCI field.\n","date":"October 9, 2023","hero":"/posts/hci/researcher/research.png","permalink":"https://melaniebrg.github.io/posts/hci/researcher/","summary":"Exploring the Pioneering HCI Research of Dr. Elizabeth Churchill Brief introduction Dr. Elizabeth Churchill, currently a Director of User Experience at Google in Mountain View, California, has drawn on social, computer, engineering and data sciences to create innovative end-user applications and services for the past 20 years.\nAcademic Background She holds a PhD from the University of Cambridge, an honorary Doctor of Science (DSc.) from the University of Sussex, and in September will be awarded an honorary doctorate from the University of Stockholm.","tags":null,"title":"Presentation of HCI researcher"},{"categories":null,"contents":"After a 6-hour lecture introducing Human-Computer Interaction (HCI), our first homework was to find real-life objects that exemplify the concepts in HCI.\nAffordances Definition Before we delve into real-life examples, let\u0026rsquo;s define what an affordance in HCI. Affordance refers to the inherent usability or functionality of an object, interface, or system. It\u0026rsquo;s a concept that suggests what actions can be performed with an object and how those actions can be intuitively understood by users.\nGood Affordance Example: The Guitar Stand One excellent example of a good affordance is a simple guitar stand. Indeed, the guitar stand provides a clear and intuitive affordance for users to place their guitars securely.\nThe mapping of where to place the guitar on the stand is straightforward. The shape of the stand corresponds to the shape of the guitar, making it easy to understand how to position the instrument. When you place a guitar on the stand, you feel a sense of stability and support. This feedback reinforces the understanding that the stand is designed for this purpose. Bad Affordance Example: The Complex Guitar Amplifier On the other hand, let\u0026rsquo;s consider a guitar amplifier with an abundance of buttons and controls as an example of a bad affordance.\nWhile the amplifier\u0026rsquo;s purpose is clear—to amplify the guitar\u0026rsquo;s sound—the multitude of buttons, knobs, and switches can overwhelm users, making it challenging to determine their functions at a glance.\nThe mapping between the controls and their effects on the sound may not be immediately evident. Users may need to consult a manual or experiment extensively to understand how to achieve their desired sound.\nHow to Improve the Guitar Amplifier\u0026rsquo;s Affordance To enhance the affordance of the guitar amplifier, several improvements can be made:\nSimplify Controls: Reduce the number of controls and group related functions together. Use labels and icons to make the purpose of each control more apparent. Visual Feedback: Incorporate more LED indicators or display screens to provide real-time visual feedback on the settings\u0026rsquo; impact on sound. Gestalt Laws Definition The Gestalt principles, developed by German psychologists, explain how humans interpret their complex surroundings. These principles help us understand why we perceive certain visual and auditory phenomena and make sense of seemingly chaotic information. There are six fundamental Gestalt principles:\nSimilarity: Similar things tend to appear grouped together, both visually and auditorily. We naturally group objects based on their similarity, such as color or sound. Prägnanz: This principle, also called the law of simplicity, suggests that our brains simplify complex objects into recognizable forms. For example, we see the Olympic logo as overlapping circles, not complex lines. Proximity: Objects physically close to each other are seen as more related. This leads to the grouping of nearby elements. Continuity: Points connected by smooth lines are perceived as related. Elements along a line or curve are seen as more connected. Closure: We perceive elements as belonging together if they complete some entity, even with missing information. Our brains fill in gaps to create meaningful patterns. Common Region: Elements within the same closed region are seen as related. This principle explains why elements within a defined boundary appear connected. Examples Here are examples of website which do not respect these laws.\nUserinyerface The game Userinyerface is a prime example of a digital interface that intentionally disregards several Gestalt Laws, creating a frustrating and confusing user experience. If you try the game you will observe that it introduces complexity and confusion in its design, challenging the notion of simplicity (Prägnanz), visual elements do not follow smooth paths or logical sequences, further adding to the disorienting experience (Continuity), consistency in color, shape, and styling is intentionally disrupted to defy user expectations (Similarity).\nThe game therefore highlights the importance of following Gestalt principles in real-world design to create user-friendly and intuitive interfaces.\nMoodle website Another example, though less critical than the game, is the login experience on the Moodle website where courses are accessed. The website design disregards Gestalt principles, leading to a potentially frustrating user experience.\nProblem: The \u0026ldquo;Connexion\u0026rdquo; (Login) button is tiny and has light text and color, making it less prominent (Prägnanz). After clicking it, users are directed to a page where they need to choose their school, introducing an unexpected step that disrupts the Law of Closure.\nCorrection: To enhance the user experience and align the design with Gestalt principles, consider implementing the following changes:\nButton Visibility: Increase the visibility of the \u0026ldquo;Connexion\u0026rdquo; button by using a contrasting color, a larger font size, or bold text to make it more prominent. This makes it easier for users to identify and initiate the login process. Streamline Login: Aim to simplify the login process. Direct users to the login form immediately after clicking the \u0026ldquo;Connexion\u0026rdquo; button. If school selection is necessary, integrate it into the login form as a dropdown menu or a clear, concise choice, rather than leading users to a separate page. Dark designs \u0026ldquo;A dark pattern is a type of user interface that appears to have been carefully crafted to trick users into doing things that are not in their interest and is usually at their expense.\u0026rdquo; Harry Brignull, a London based UX designer.\nForced Continuity When you have to start your free trial by adding your card details, or you need to enter your email to continue using a website or an app. Choosing to skip these self-interest gimmicks is not an option in forced continuity.\nTo improve the design :\nTransparent Cart Explicit consent Confirmation Roach Motel The Roach Motel design pattern makes it easy for users to sign up for a service or subscription but incredibly difficult for them to cancel or unsubscribe.\nTo redesign for an ethical use :\nClear Cancelation Process Confirmation and Feedback Transparent Pricing ","date":"September 30, 2023","hero":"/posts/hci/affordance/vox_front.jpg","permalink":"https://melaniebrg.github.io/posts/hci/affordance/","summary":"After a 6-hour lecture introducing Human-Computer Interaction (HCI), our first homework was to find real-life objects that exemplify the concepts in HCI.\nAffordances Definition Before we delve into real-life examples, let\u0026rsquo;s define what an affordance in HCI. Affordance refers to the inherent usability or functionality of an object, interface, or system. It\u0026rsquo;s a concept that suggests what actions can be performed with an object and how those actions can be intuitively understood by users.","tags":null,"title":"Affordance in daily life"},{"categories":null,"contents":"Introduction In this article, I will walk you through the process of developing a rollerball game in Unity, where the player controls a ball on a plane, collecting stars while avoiding red enemies. My game includes both static and shooter enemies, a health system with three lives, and a Game Over screen that allows players to restart or exit the game. Let\u0026rsquo;s dive into the development process step by step.\nGame development Create the Ground, Walls, and Ball The initial step in crafting my rollerball game was setting up the game environment. I meticulously created a ground plane, enclosed it with walls to establish the play area, and strategically positioned the controllable ball at the center.\nAnimate the Ball with a Script Then I created a script to handle the ball\u0026rsquo;s animation, allowing it to roll smoothly on the ground plane and respond to user input.\nCollectibles Counter The goal of the game is to collect as many stars as possible. To do so a counter is displayed in the user interface\nHealth system I implemented a three-lives health system, adding depth to the game\u0026rsquo;s challenge. When a player lost all three lives, a \u0026ldquo;Game Over\u0026rdquo; screen would appear, offering the choice to either restart or exit the game. Unity\u0026rsquo;s user-friendly UI system streamlined the process of creating this pivotal feature.\nShooting ennemy I designed two distinct types of enemies: static and shooter. The static enemy remained stationary, and contact with it led to a life loss. The shooter enemy, on the other hand, utilized Unity\u0026rsquo;s AI Navigation system to pursue the player and shoot projectiles, adding an extra layer of challenge to the game.\nDemonstration on Computer Here is a little demo of the game :\nExtension to mobile game The game currently works on a computer, but the next step is to make it mobile-friendly. I tested it on an iPhone 14 Pro Max Emulator in Xcode. Here are the necessary steps:\nAdd the necessary modules: Unity Hub \u0026gt; Installs \u0026gt; Add Modules and add iOS build support.\nAdjust the game for the emulator by changing the setting to Player Settings \u0026gt; Target SDK: Simulator SDK.\nOpen Xcode and launch the RollerBall app on the emulator.\nExtension to VR game I also built a version for a VR Hololens headset, following my professor\u0026rsquo;s tutorial:\nInstall the OpenXR Plugin and XR Interaction Toolkit from the Package Manager (Unity Registry).\nGo to Edit \u0026gt; Project Settings \u0026gt; XR Plug-in Management and enable OpenXR.\nIn the hierarchy, create an XR Origin by right-clicking: XR \u0026gt; XR Origin (VR).\nAdd Character Controller and Character Controller Driver to the XR Origin. Ensure that the Origin Base GO is set to XR Origin.\nDelete the default main camera from the Hierarchy.\nRight-click in the Hierarchy, go to XR \u0026gt; Locomotion System (Action based), and untick Teleportation and Snap Turn Provider. In the Add component, add Continuous Move and Continuous Turn Provider (action-based). Drag and drop the XR rig and Locomotion System. Make sure Input Action Manager is set in the XR Origin.\nSet the hand XR controller parameters correctly.\nCreate an empty Prefab (HandController) in the Prefabs folder, creating a square and a cylinder to form a remote controller shape. Add it to the model prefab of the hand controller. Add a sphere collider to be able to grab objects. Add XR Direct Interactor and XR Grab Interactable to the PlayBoard.\nCreate an empty game object called AttachPoint and set it as the AttachTransform parameter.\nNow you can immerse yourself in the game and use your hands as controllers.\nThe next step, if time allows, is to create a room and make the playboard smaller to fit inside the room.\n","date":"September 30, 2023","hero":"/posts/hci/simple-unity-project/rollerball.png","permalink":"https://melaniebrg.github.io/posts/hci/simple-unity-project/","summary":"Introduction In this article, I will walk you through the process of developing a rollerball game in Unity, where the player controls a ball on a plane, collecting stars while avoiding red enemies. My game includes both static and shooter enemies, a health system with three lives, and a Game Over screen that allows players to restart or exit the game. Let\u0026rsquo;s dive into the development process step by step.","tags":null,"title":"Developing a Rollerball Game in Unity"},{"categories":null,"contents":"Introduction: Getting started with game development is an exciting journey, and Unity is an essential tool for aspiring developers. Thanks to the helpful guidance of my teacher, Léa Saunier, I successfully installed Unity on my M1 Mac computer. In this article, I\u0026rsquo;ll provide a brief step-by-step guide on how to install Unity based on Léa Saunier\u0026rsquo;s tutorial.\nStep 1: Download Unity Hub Begin by downloading Unity Hub from https://unity.com/download. Unity Hub acts as a central management tool for your Unity projects and installations.\nStep 2: Connect Your Account/License Open Unity Hub and log in with your Unity account or license to access Unity\u0026rsquo;s features and manage your licenses.\nStep 3: Install Unity 2022.3.2f1 Install the recommended Unity version, 2022.3.2f1, by clicking this link: unityhub://2022.3.2f1/d74737c6db50. Unity Hub will handle the installation process for you.\nStep 4: Install Required Modules Customize your Unity installation by installing modules for specific platforms like iOS, Windows, or Android. Unity Hub simplifies the process by allowing you to select the modules you need.\nStep 5: Install a Code Editor It\u0026rsquo;s highly recommended to install Visual Studio alongside Unity. This option will provide a robust code editor and seamlessly integrate with Unity. Unity will prompt you to install the Unity plugin for Visual Studio to enhance your workflow.\nStep 6 : Enjoy ! ","date":"September 30, 2023","hero":"/posts/hci/unity-install/unityinstall.png","permalink":"https://melaniebrg.github.io/posts/hci/unity-install/","summary":"Introduction: Getting started with game development is an exciting journey, and Unity is an essential tool for aspiring developers. Thanks to the helpful guidance of my teacher, Léa Saunier, I successfully installed Unity on my M1 Mac computer. In this article, I\u0026rsquo;ll provide a brief step-by-step guide on how to install Unity based on Léa Saunier\u0026rsquo;s tutorial.\nStep 1: Download Unity Hub Begin by downloading Unity Hub from https://unity.com/download. Unity Hub acts as a central management tool for your Unity projects and installations.","tags":null,"title":"Unity Installation"},{"categories":["blender"],"contents":"After a 9-hour introductory class to Blender, I took on the challenge of creating a 3D model of my Taylor 510ce guitar. In this article, I\u0026rsquo;ll walk you through the steps I followed to bring this project to life.\nGathering Reference image To start, I began by capturing reference photos of my guitar from both side and front angles. I then removed the background of these images using Photoshop and put them as background images on x and y axis in Blender.\nSetting Up Background Images With my reference images prepared, I imported them into Blender and positioned them as background images on both the X and Y axes. These images served as blueprints, helping me maintain the accurate proportions and details of the guitar throughout the modeling process.\nModeling the Guitar The core of this project was modeling the guitar\u0026rsquo;s intricate shape. I began by using Blender\u0026rsquo;s Knife tool to outline the guitar\u0026rsquo;s body on a plane. Afterward, I extruded and adjusted vertices to match the contours and dimensions of the reference images. Moving on to the neck and headstock, I created these components using cube primitives. I then proceeded to model other components such as the head, bridge, strings, and smaller details like the rosette, pickguard, and tuners.\nApplying Textures Once satisfied with the 3D structure, I shifted my attention to applying textures to the model. I used the reference pictures to ensure the textures were authentically replicated.\nCreating the Scene To showcase the 3D guitar effectively, I created a virtual room environment within Blender. Adjusting the lighting and spotlights helped illuminate the guitar in a way that highlighted its details.\nCrafting the Animation Finally, to provide a multifaceted view of the guitar, I created a simple camera animation.\n","date":"September 28, 2023","hero":"/posts/cg/blender-project/taylor_guitar.jpg","permalink":"https://melaniebrg.github.io/posts/cg/blender-project/","summary":"After a 9-hour introductory class to Blender, I took on the challenge of creating a 3D model of my Taylor 510ce guitar. In this article, I\u0026rsquo;ll walk you through the steps I followed to bring this project to life.\nGathering Reference image To start, I began by capturing reference photos of my guitar from both side and front angles. I then removed the background of these images using Photoshop and put them as background images on x and y axis in Blender.","tags":["blender"],"title":"Blender project : My guitar in 3D !"},{"categories":null,"contents":"As part of my Human-Computer Interface class, I was tasked with creating a blog to showcase my work during my master\u0026rsquo;s program. I opted to build my website using Hugo, a fast and modern static site generator. In this guide, I will walk you through the steps to set up your own portfolio website using Hugo and deploy it on GitHub Pages.\nHere are the different steps to set up this portfolio :\nInstallation on MacOs Open a terminal and execute the following command to install Hugo using Homebrew: brew install hugo Visit the Hugo Themes website and choose the Toha theme. Then, access the Github repository. Fork the repository and rename it to [your GitHub username].github.io Clone the repository to your local machine: git clone https://github.com/[your GitHub username]/[your GitHub username].github.io.git Website personalization Once you have cloned the repository, open the project in Visual Studio Code or your preferred text editor. Modify the config.yaml file and set baseURL = https://[your github username].github.io. Choose the languages you want to use for the website Customize the template to suit your needs. You can use YAML files in the /data directory for the portfolio page and create blog articles in the /content/posts . Visualize your website locally with the following command hugo server -D Deployment in Github Pages Ensure that your repository name is [your GitHub username].github.io Create a gh-pages branch typing the following command : git checkout -b gh-pages Push the gh-pages branch to Github : git push origin gh-pages Check if the template provides a workflow in .github/workflows/deploy-site.yaml for automated deployments using GitHub Actions. Go back to the main branch and push all your changes Your portfolio website is now accessible at https://[your github username].github.io ","date":"September 23, 2023","hero":"/posts/hci/blog-creation/blog.png","permalink":"https://melaniebrg.github.io/posts/hci/blog-creation/","summary":"As part of my Human-Computer Interface class, I was tasked with creating a blog to showcase my work during my master\u0026rsquo;s program. I opted to build my website using Hugo, a fast and modern static site generator. In this guide, I will walk you through the steps to set up your own portfolio website using Hugo and deploy it on GitHub Pages.\nHere are the different steps to set up this portfolio :","tags":null,"title":"Creating a Portfolio Website with Hugo and Deploying on GitHub Pages"},{"categories":["blog"],"contents":"Welcome to the blog section of my portfolio website, where I present some of my work, projects, and experiments in:\nHCI : Human-Computer Interface CG : Computer Graphics DL : Deep learning ","date":"September 22, 2023","hero":"/posts/introduction/space.jpg","permalink":"https://melaniebrg.github.io/posts/introduction/","summary":"Welcome to the blog section of my portfolio website, where I present some of my work, projects, and experiments in:\nHCI : Human-Computer Interface CG : Computer Graphics DL : Deep learning ","tags":["Introduction","Blog"],"title":"Introduction"},{"categories":null,"contents":"Go Notes ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://melaniebrg.github.io/notes/go/_index.bn/","summary":"Go Notes ","tags":null,"title":"Go এর নোট সমূহ"}]